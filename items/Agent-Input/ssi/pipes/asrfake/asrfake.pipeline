<?xml version="1.0" encoding="utf-16" standalone="yes"?>
<pipeline>

	<register>
		<load name="browser" />		
		<load name="ioput" />	
		<load name="audio" />	
		<load name="graphic" />	
		<load name="asrfake" />	
		<load name="activemq" />	
		<load name="camera"/>
		<load name="ffmpeg"/>		
	</register>	
	
	<!-- audio sensor -->
	<sensor create="Audio" option="options/audio" scale="true" blockInSamples="512">
		<output channel="audio" pin="audio"/>
	</sensor>
	
	<!-- activity detection -->
	<transformer create="AudioActivity" method="0" threshold="0.05">
		<input pin="audio" frame="0.03s" delta="0.015s"/>
		<output pin="vad"/>
	</transformer>
	<consumer create="ZeroEventSender" mindur="0.3" maxdur="5.0" eager="true" hangin="3" hangout="30" address="vad@audio">
		<input pin="vad" frame="0.1s"/>
	</consumer>
	
	<!-- send asr string -->
	<object create="AsrFake" sname="audio" ename="asr" path="$(file)">
		<listen address="vad@audio" state="completed"/>
	</object>
	<object create="XMLEventSender:monitor" address="asr@xml" path="asrfake.xml" monitor="true" mname="RESULT" console="false" update="100" coldelim=" ">
		<listen address="vad,asr@audio"/>
	</object>
	<gate open="$(activemq:use)">
		<object create="ActiveMQEventSender" brokerURI="$(activemq:uri)" id="$(activemq:id)" topic="$(activemq:topic)">
			<listen address="asr@xml"/>
		</object>
	</gate>
		
	<!-- send stimuli -->
	<object create="Stimuli" address="url@stimuli" extension="*.html" startName="questions/001_question.html" folder="answers">
		<listen address="vad@audio" state="completed"/>
	</object>
	
	<!-- diplay audio -->
	<consumer create="SignalPainter:plot" type="2" size="10" title="AUDIO" autoscale="false" fix="-1.0,1.0">
		<input pin="audio" frame="0.01s"/>
	</consumer>
	
	<!-- play back -->
	<object create="SoundPlayer">
		<listen address="url@stimuli"/>
	</object>
	
	<!-- display stimuli -->
	<object create="Browser:browser" title="BROWSER">
		<listen address="url@stimuli"/>
	</object>
	
	<!-- capture user -->
	<gate open="$(capture:use)">
	
		<!-- capture user -->
		<gate open="$(capture:user)">
		
			<sensor create="Camera" option="options/camera" flip="true" >
				<output channel="video" pin="camera" size="2.0"/>
			</sensor>	
			<consumer create="FFMPEGWriter" url="$(capture:dir)/$(date)_user.mp4">
				<input pin="camera;audio" frame="1"/>				
			</consumer>	
			<consumer create="VideoPainter:vplot" title="CAMERA" flip="false" pos="20,620,320,240">
				<input pin="camera" frame="1" delta="0"/>
			</consumer>			
			
		</gate>
		
		<!-- capture screen -->
		<gate open="$(capture:screen)">
		
			<!-- audio sensor -->
			<sensor create="Audio" option="options/audio_mix" scale="true" blockInSamples="512">
				<output channel="audio" pin="audio_mix"/>
			</sensor>
			<sensor create="CameraScreen" full="false" region="400,0,800,600" fps="25">
				<output channel="video" pin="screen" size="2.0"/>
			</sensor>			
			<consumer create="FFMPEGWriter" url="$(capture:dir)/$(date)_screen.mp4">
				<input pin="screen;audio_mix" frame="1"/>				
			</consumer>				
			<consumer create="VideoPainter:vplot" title="SCREEN" flip="false" pos="340,620,320,240">
				<input pin="screen" frame="1" delta="0"/>
			</consumer>			
		
		</gate>
		
	</gate>
	
	<!-- decoration -->
	<object create="Decorator" icon="true" title="Pipeline">
		<area pos="0,0,400,600">console</area>
		<area pos="800,0,400,300">plot*</area>			
		<area pos="400,0,400,600">browser*</area>
		<area pos="800,300,400,300">monitor*</area>
	</object>	
		
</pipeline>